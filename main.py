import os
import json
from dotenv import load_dotenv
from langchain.llms.openai import OpenAI
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

load_dotenv(".env")


def analyze_code(input_code : str, input_cve : str, key: str) -> str:
    """
    Sends code to OpenAI model for analysis

    Parameters
    -------------------
    input_code (some decsri)

    Return
    -------------------

    """

    # create a prompt template
    template = """
    You are an AI assistant that helps users analyse their code for security vulnerabilities
    You answer truthfully and say "I don't know" when questions are difficult for you to answer. 
    You think carefully, step by step, to avoid making mistakes and are an expert in secure coding practices. 

    Here is a user's code: 
    <?php
    $file = $_GET['file']; // Get input file
    $data = file_get_contents($file); // Read file content
    eval($data); // Execute code from the file
    ?>

    Analyse the code for the following vulnerability: Ignition before 2.5.2, as used in Laravel and other products, allows unauthenticated remote attackers to execute arbitrary code because of insecure usage of file_get_contents() and file_put_contents(). This is exploitable on sites using debug mode with Laravel before 8.4.2.

    Reasoning: In this vulnerable code snippet, an attacker can manipulate the file parameter in the GET request to include a malicious PHP file. This file is then read using `file_get_contents()` and executed using `eval()`, allowing the attacker to execute arbitrary code on the server.

    Answer: The code is vulnerable due to unvalidated inputs to the `file_get_contents()` function.

    Here is a user's code: {user_code}
    Analyse the code for the following vulnerability: {cve_description}

    Reasoning: 
    """

    prompt = PromptTemplate.from_template(template)
    llm = OpenAI(openai_api_key=key)

    # create and run a chain
    chain = LLMChain(prompt=prompt, llm=llm)
    user_code = input_code
    with open('./cve_details.json', 'r') as json_file:
        data = json.load(json_file)
        cve_description = data.get(input_cve)
        # print(f"debgugging: {cve_description}")

    out = chain.invoke({'user_code': user_code, 'cve_description': cve_description})
    return out["text"]